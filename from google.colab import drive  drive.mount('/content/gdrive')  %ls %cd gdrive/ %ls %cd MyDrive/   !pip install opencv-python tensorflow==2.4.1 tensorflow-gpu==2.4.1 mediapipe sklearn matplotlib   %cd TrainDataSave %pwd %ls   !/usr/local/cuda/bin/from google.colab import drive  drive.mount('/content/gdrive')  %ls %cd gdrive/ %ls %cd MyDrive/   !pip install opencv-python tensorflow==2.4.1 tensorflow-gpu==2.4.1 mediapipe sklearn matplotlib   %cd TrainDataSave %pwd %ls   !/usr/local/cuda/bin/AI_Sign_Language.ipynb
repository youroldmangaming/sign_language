from google.colab import drive 
drive.mount('/content/gdrive')

%ls
%cd gdrive/
%ls
%cd MyDrive/


!pip install opencv-python tensorflow==2.4.1 tensorflow-gpu==2.4.1 mediapipe sklearn matplotlib


%cd TrainDataSave
%pwd
%ls


!/usr/local/cuda/bin/nvcc --version

!nvidia-smi

pip install sklearn

!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib

from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import numpy as np
import os

#DATA_PATH = os.path.join('TrainDataSave')
#yDATA_PATH = os.path.join('.')

sequence_length = 30


gestures= np.array(['last','night', 'watch','funny','video', 'you','tube'])

label_map = {label:num for num, label in enumerate(gestures)}

label_map

sequences, labels = [], []
for gesture in gestures:
    for sequence in np.array(os.listdir(os.path.join('.', gesture))).astype(int):
        window = []
        for frame_num in range(sequence_length):
            res = np.load(os.path.join('.', gesture, str(sequence), "{}.npy".format(frame_num)))
            window.append(res)
        sequences.append(window)
        labels.append(label_map[gesture])




pip install gmaps

import gmaps
from google.colab import output
output.enable_custom_widget_manager()

gmaps.configure(api_key='AIzaSyBtGggubSrw7fo1Lr9r4luTWamyr0aEsX4')

marker_locations = [
(-34.0, -59.166672),
(-32.23333, -64.433327),
(40.166672, 44.133331),
(51.216671, 5.0833302),
(51.333328, 4.25)
]
 
 
fig = gmaps.figure()
markers = gmaps.marker_layer(marker_locations)
fig.add_layer(markers)
fig

#fig = gmaps.figure()
#fig

np.array(sequences).shape



np.array(labels).shape


X = np.array(sequences)
X.shape

y = to_categorical(labels).astype(int)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)
y_test.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import TensorBoard

log_dir = os.path.join('Logs')
tb_callback = TensorBoard(log_dir=log_dir)
model = Sequential()
model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))
model.add(LSTM(128, return_sequences=True, activation='relu'))
model.add(LSTM(64, return_sequences=False, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(gestures.shape[0], activation='softmax'))

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])

model.summary()


res = model.predict(X_test)
gestures[np.argmax(res[0])]


model.save('gestures.h5')
#del model
#model.load_weights('gestures.h5')


#model = Sequential()
#model.load_weights('gestures.h5')

from sklearn.metrics import multilabel_confusion_matrix, accuracy_score
yhat = model.predict(X_test)

ytrue = np.argmax(y_test, axis=1).tolist()
yhat = np.argmax(yhat, axis=1).tolist()

multilabel_confusion_matrix(ytrue, yhat)

accuracy_score(ytrue, yhat)

from scipy import stats
import cv2 as cv
from matplotlib import pyplot as plt

colors = [(245,117,16), (117,245,16), (16,117,245)]
def prob_viz(res, gestures, input_frame, colors):
    output_frame = input_frame.copy()
    for num, prob in enumerate(res):
        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)
        cv2.putText(output_frame, gestures[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)
        
    return output_frame
plt.figure(figsize=(18,18))
plt.imshow(prob_viz(res, gestures, image, colors))


from google.colab import drive 
drive.mount('/content/gdrive')

%ls
%cd gdrive/
%ls
%cd MyDrive/


!pip install opencv-python tensorflow==2.4.1 tensorflow-gpu==2.4.1 mediapipe sklearn matplotlib


%cd TrainDataSave
%pwd
%ls


!/usr/local/cuda/bin/nvcc --version

!nvidia-smi

pip install sklearn

!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib

from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import numpy as np
import os

#DATA_PATH = os.path.join('TrainDataSave')
#yDATA_PATH = os.path.join('.')

sequence_length = 30


gestures= np.array(['last','night', 'watch','funny','video', 'you','tube'])

label_map = {label:num for num, label in enumerate(gestures)}

label_map

sequences, labels = [], []
for gesture in gestures:
    for sequence in np.array(os.listdir(os.path.join('.', gesture))).astype(int):
        window = []
        for frame_num in range(sequence_length):
            res = np.load(os.path.join('.', gesture, str(sequence), "{}.npy".format(frame_num)))
            window.append(res)
        sequences.append(window)
        labels.append(label_map[gesture])




pip install gmaps

import gmaps
from google.colab import output
output.enable_custom_widget_manager()

gmaps.configure(api_key='AIzaSyBtGggubSrw7fo1Lr9r4luTWamyr0aEsX4')

marker_locations = [
(-34.0, -59.166672),
(-32.23333, -64.433327),
(40.166672, 44.133331),
(51.216671, 5.0833302),
(51.333328, 4.25)
]
 
 
fig = gmaps.figure()
markers = gmaps.marker_layer(marker_locations)
fig.add_layer(markers)
fig

#fig = gmaps.figure()
#fig

np.array(sequences).shape



np.array(labels).shape


X = np.array(sequences)
X.shape

y = to_categorical(labels).astype(int)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)
y_test.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import TensorBoard

log_dir = os.path.join('Logs')
tb_callback = TensorBoard(log_dir=log_dir)
model = Sequential()
model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))
model.add(LSTM(128, return_sequences=True, activation='relu'))
model.add(LSTM(64, return_sequences=False, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(gestures.shape[0], activation='softmax'))

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])

model.summary()


res = model.predict(X_test)
gestures[np.argmax(res[0])]


model.save('gestures.h5')
#del model
#model.load_weights('gestures.h5')


#model = Sequential()
#model.load_weights('gestures.h5')

from sklearn.metrics import multilabel_confusion_matrix, accuracy_score
yhat = model.predict(X_test)

ytrue = np.argmax(y_test, axis=1).tolist()
yhat = np.argmax(yhat, axis=1).tolist()

multilabel_confusion_matrix(ytrue, yhat)

accuracy_score(ytrue, yhat)

from scipy import stats
import cv2 as cv
from matplotlib import pyplot as plt

colors = [(245,117,16), (117,245,16), (16,117,245)]
def prob_viz(res, gestures, input_frame, colors):
    output_frame = input_frame.copy()
    for num, prob in enumerate(res):
        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)
        cv2.putText(output_frame, gestures[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)
        
    return output_frame
plt.figure(figsize=(18,18))
plt.imshow(prob_viz(res, gestures, image, colors))


